{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXVbSluhDGTuaeb7lJKMla",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-adithya-0925/ml-project/blob/main/cnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYjIB3zUjux1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive to access the dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the paths to your dataset directory in Google Drive\n",
        "dataset_dir = '/content/drive/MyDrive/plant ml/Indian Medicinal Leaves Image Datasets'\n",
        "img_width, img_height = 150, 150  # You can adjust these dimensions\n",
        "\n",
        "# Define the number of classes (types of plants)\n",
        "num_classes = len(os.listdir(dataset_dir))  # Automatically count the subfolders\n",
        "\n",
        "# Create an ImageDataGenerator to preprocess and augment your data\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Split 20% of the data for validation\n",
        ")\n",
        "\n",
        "# Load the dataset using flow_from_directory\n",
        "generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Use the training subset\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Use the validation subset\n",
        ")\n",
        "\n",
        "# Create the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    generator,\n",
        "    steps_per_epoch=generator.samples // 32,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // 32\n",
        ")\n",
        "\n",
        "# Save the model for future use\n",
        "model.save('/content/drive/My Drive/plant_model.h5')\n",
        "\n",
        "# Now, you can use this trained model to identify plants\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/plant_model.h5')\n",
        "\n",
        "# Use the model to identify a plant from an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def identify_plant(image_path):\n",
        "    img = image.load_img(image_path, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.0  # Normalize the image\n",
        "\n",
        "    result = model.predict(img)\n",
        "    class_indices = generator.class_indices\n",
        "    inv_map = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class = inv_map[np.argmax(result)]\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "import os\n",
        "\n",
        "app = Flask(__name)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('relcam.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "    if file:\n",
        "        img = image.load_img(file, target_size=(img_width, img_height))\n",
        "        img = image.img_to_array(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = img / 255.0  # Normalize the image\n",
        "\n",
        "        result = model.predict(img)\n",
        "        class_indices = generator.class_indices\n",
        "        inv_map = {v: k for k, v in class_indices.items()}\n",
        "        predicted_class = inv_map[np.argmax(result)]\n",
        "\n",
        "        return f'The identified plant is: {predicted_class}'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n"
      ]
    }
  ]
}